# ROCm-enabled Dockerfile for AMD GPU support
# Build with: docker build -f Dockerfile.rocm -t tts-service:rocm .
#
# Latest ROCm 7.1 with PyTorch 2.8.0 and Ubuntu 22.04

FROM rocm/pytorch:rocm7.1_ubuntu22.04_py3.10_pytorch_release_2.8.0

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3-pip \
    build-essential \
    libsndfile1 \
    ffmpeg \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip
RUN python -m pip install --upgrade pip

WORKDIR /app

# Copy requirements
COPY requirements-gpu.txt .

# Install Python dependencies
# PyTorch with ROCm support is already included in base image
RUN pip install --no-cache-dir -r requirements-gpu.txt

# Accept Coqui TTS license agreement for XTTS-v2 model
ENV COQUI_TOS_AGREED=1

# Download XTTS-v2 model on build (use gpu=False for build compatibility)
# Actual GPU usage is determined at runtime by XTTSModel class
RUN python -c "from TTS.api import TTS; TTS('tts_models/multilingual/multi-dataset/xtts_v2', gpu=False)"

# Copy source code
COPY . .

# Create necessary directories
RUN mkdir -p /app/voices /app/cache

# Expose port
EXPOSE 8000

# Environment variables for ROCm
# These can be overridden via docker-compose or .env
ENV HSA_ENABLE_SDMA=0

# GPU architecture (gfx target) - can be overridden via GPU_ARCH env var
# Common values:
#   - gfx1030: RX 6000 series (RDNA 2)
#   - gfx1100: RX 7000 series (RDNA 3)
#   - gfx90a: MI200 series
ARG GPU_ARCH=gfx1030
ENV PYTORCH_ROCM_ARCH=${GPU_ARCH}

# Start FastAPI server
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
